{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Gaussian Mixture Models with EM\n",
    "\n",
    "In this assignment you will\n",
    "* implement the EM algorithm for a Gaussian mixture model\n",
    "* apply your implementation to cluster images\n",
    "* explore clustering results and interpret the output of the EM algorithm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v2.0.1) is available! Your current version is v1.10.1.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import copy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "To help us develop and test our implementation, we will generate some observations from a mixture of Gaussians and then run our EM algorithm to discover the mixture components. We'll begin with a function to generate the data, and a quick plot to visualize its output for a 2-dimensional mixture of three Gaussians.\n",
    "\n",
    "Now we will create a function to generate data from a mixture of Gaussians model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_MoG_data(num_data, means, covariances, weights):\n",
    "    \"\"\" Creates a list of data points \"\"\"\n",
    "    num_clusters = len(weights)\n",
    "    data = []\n",
    "    for i in range(num_data):\n",
    "        #  Use np.random.choice and weights to pick a cluster id greater than or equal to 0 and less than num_clusters.\n",
    "        k = np.random.choice(len(weights), 1, p=weights)[0]\n",
    "\n",
    "        # Use np.random.multivariate_normal to create data from this cluster\n",
    "        x = np.random.multivariate_normal(means[k], covariances[k])\n",
    "\n",
    "        data.append(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "init_means = [\n",
    "    [5, 0], # mean of cluster 1\n",
    "    [1, 1], # mean of cluster 2\n",
    "    [0, 5]  # mean of cluster 3\n",
    "]\n",
    "init_covariances = [\n",
    "    [[.5, 0.], [0, .5]], # covariance of cluster 1\n",
    "    [[1., .7], [0, .7]], # covariance of cluster 2\n",
    "    [[.5, 0.], [0, .5]]  # covariance of cluster 3\n",
    "]\n",
    "init_weights = [1/4., 1/2., 1/4.]  # weights of each cluster\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(4)\n",
    "data = generate_MoG_data(100, init_means, init_covariances, init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint passed!\n"
     ]
    }
   ],
   "source": [
    "assert len(data) == 100\n",
    "assert len(data[0]) == 2\n",
    "print 'Checkpoint passed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngvv/nXVsUX6adYgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16948470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "d = np.vstack(data)\n",
    "plt.plot(d[:,0], d[:,1],'ko')\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log likelihood \n",
    "We provide a function to calculate log likelihood for mixture of Gaussians. The log likelihood quantifies the probability of observing a given set of data under a particular setting of the parameters in our model. We will use this to assess convergence of our EM algorithm; specifically, we will keep looping through EM update steps until the log likehood ceases to increase at a certain rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(Z):\n",
    "    \"\"\" Compute log(\\sum_i exp(Z_i)) for some array Z.\"\"\"\n",
    "    return np.max(Z) + np.log(np.sum(np.exp(Z - np.max(Z))))\n",
    "\n",
    "def loglikelihood(data, weights, means, covs):\n",
    "    \"\"\" Compute the loglikelihood of the data for a Gaussian mixture model with the given parameters. \"\"\"\n",
    "    num_clusters = len(means)\n",
    "    num_dim = len(data[0])\n",
    "    \n",
    "    ll = 0\n",
    "    for d in data:\n",
    "        \n",
    "        Z = np.zeros(num_clusters)\n",
    "        for k in range(num_clusters):\n",
    "            \n",
    "            # Compute (x-mu)^T * Sigma^{-1} * (x-mu)\n",
    "            delta = np.array(d) - means[k]\n",
    "            exponent_term = np.dot(delta.T, np.dot(np.linalg.inv(covs[k]), delta))\n",
    "            \n",
    "            # Compute loglikelihood contribution for this data point and this cluster\n",
    "            Z[k] += np.log(weights[k])\n",
    "            Z[k] -= 1/2. * (num_dim * np.log(2*np.pi) + np.log(np.linalg.det(covs[k])) + exponent_term)\n",
    "            \n",
    "        # Increment loglikelihood contribution of this data point across all clusters\n",
    "        ll += log_sum_exp(Z)\n",
    "        \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementation\n",
    "\n",
    "You will now complete an implementation that can run EM on the data you just created. It uses the `loglikelihood` function we provided above.\n",
    "\n",
    "Fill in the places where you find ## YOUR CODE HERE. There are seven places in this function for you to fill in.\n",
    "\n",
    "Hint: Some useful functions\n",
    "\n",
    "* [multivariate_normal.pdf](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.multivariate_normal.html): lets you compute the likelihood of seeing a data point in a multivariate Gaussian distribution.\n",
    "* [np.outer](http://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html): comes in handy when estimating the covariance matrix from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def EM(data, init_means, init_covariances, init_weights, maxiter=1000, thresh=1e-4):\n",
    "    \n",
    "    # Make copies of initial parameters, which we will update during each iteration\n",
    "    means = init_means[:]\n",
    "    covariances = init_covariances[:]\n",
    "    weights = init_weights[:]\n",
    "    \n",
    "    # Infer dimensions of dataset and the number of clusters\n",
    "    num_data = len(data)\n",
    "    num_dim = len(data[0])\n",
    "    num_clusters = len(means)\n",
    "    \n",
    "    # Initialize some useful variables\n",
    "    resp = np.zeros((num_data, num_clusters))\n",
    "    ll = loglikelihood(data, weights, means, covariances)\n",
    "    ll_trace = [ll]\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        if i % 5 == 0:\n",
    "            print(\"Iteration %s\" % i)\n",
    "        \n",
    "        # E-step: compute responsibilities\n",
    "        # Update resp matrix so that resp[j, k] is the responsibility of cluster k for data point j.\n",
    "        # Hint: To compute likelihood of seeing data point j given cluster k, use multivariate_normal.pdf.\n",
    "        for j in range(num_data):\n",
    "            for k in range(num_clusters):\n",
    "                # YOUR CODE HERE\n",
    "                resp[j, k] = multivariate_normal.pdf(data[j], means[k],covariances[k])\n",
    "        row_sums = resp.sum(axis=0)\n",
    "        resp = resp / row_sums # normalize over all possible cluster assignments\n",
    "\n",
    "        # M-step\n",
    "        # Compute the total responsibility assigned to each cluster, which will be useful when \n",
    "        # implementing M-steps below. In the lectures this is called N^{soft}\n",
    "        counts = np.sum(resp, axis=1)\n",
    "        \n",
    "        for k in range(num_clusters):\n",
    "            \n",
    "            # Update the weight for cluster k using the M-step update rule for the cluster weight, \\hat{\\pi}_k.\n",
    "            # YOUR CODE HERE\n",
    "            weights[k] = counts[k]/num_data\n",
    "            \n",
    "            # Update means for cluster k using the M-step update rule for the mean variables.\n",
    "            # This will assign the variable means[k] to be our estimate for \\hat{\\mu}_k.\n",
    "            weighted_sum = 0\n",
    "            for j in range(num_data):\n",
    "                # YOUR CODE HERE\n",
    "                weighted_sum += data[j][k] * weights[k]\n",
    "            # YOUR CODE HERE\n",
    "            means[k] = weighted_sum/num_data\n",
    "            \n",
    "            # Update covariances for cluster k using the M-step update rule for covariance variables.\n",
    "            # This will assign the variable covariances[k] to be the estimate for \\hat{\\Sigma}_k.\n",
    "            weighted_sum = np.zeros((num_dim, num_dim))\n",
    "            for j in range(num_data):\n",
    "                # YOUR CODE HERE (Hint: Use np.outer on the data[j] and this cluster's mean)\n",
    "                weighted_sum += data[j][k] * weights[k]\n",
    "            # YOUR CODE HERE\n",
    "            means[k] = weighted_sum/num_data\n",
    "            covariances[k] = sum(np.outer((data[j]-means[k]),(data[j]-means[k]).T))\n",
    "          \n",
    "        \n",
    "        # Compute the loglikelihood at this iteration\n",
    "        # YOUR CODE HERE\n",
    "        ll_latest = loglikelihood(data, weights[k], means[k], covariances[k])\n",
    "        ll_trace.append(ll_latest)\n",
    "        \n",
    "        # Check for convergence in log-likelihood and store\n",
    "        if (ll_latest - ll) < thresh and ll_latest > -np.inf:\n",
    "            break\n",
    "        ll = ll_latest\n",
    "    \n",
    "    if i % 5 != 0:\n",
    "        print(\"Iteration %s\" % i)\n",
    "    \n",
    "    out = {'weights': weights, 'means': means, 'covs': covariances, 'loglik': ll_trace, 'resp': resp}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.35027466],\n",
       "       [ 0.39930994],\n",
       "       [ 5.78687806],\n",
       "       [ 4.42354774],\n",
       "       [ 4.57178392],\n",
       "       [ 5.37524938],\n",
       "       [ 5.0153992 ],\n",
       "       [ 4.43019984],\n",
       "       [ 3.19079704],\n",
       "       [ 4.34340969],\n",
       "       [ 7.8907068 ],\n",
       "       [ 4.72055605],\n",
       "       [ 4.13180207],\n",
       "       [ 3.36653569],\n",
       "       [ 2.56658302],\n",
       "       [ 1.56054575],\n",
       "       [ 1.97368429],\n",
       "       [ 5.47473875],\n",
       "       [ 5.4806719 ],\n",
       "       [ 3.25469483],\n",
       "       [ 5.93407266],\n",
       "       [ 4.36406415],\n",
       "       [ 2.06563172],\n",
       "       [ 2.10336466],\n",
       "       [ 4.82421663],\n",
       "       [ 6.51925608],\n",
       "       [ 1.93872858],\n",
       "       [ 5.57581396],\n",
       "       [ 1.37462539],\n",
       "       [ 3.85072665],\n",
       "       [ 4.54526012],\n",
       "       [ 1.07774361],\n",
       "       [ 0.84535509],\n",
       "       [ 3.54326046],\n",
       "       [ 2.23873855],\n",
       "       [ 5.98217156],\n",
       "       [ 1.91863706],\n",
       "       [ 4.78354559],\n",
       "       [ 6.79403477],\n",
       "       [-0.7168747 ],\n",
       "       [ 4.62793812],\n",
       "       [ 4.21308881],\n",
       "       [ 2.3061229 ],\n",
       "       [ 1.4274007 ],\n",
       "       [ 4.85141367],\n",
       "       [ 6.20226287],\n",
       "       [-1.32300485],\n",
       "       [ 3.32013297],\n",
       "       [ 4.47323689],\n",
       "       [ 5.81549841],\n",
       "       [ 4.32642219],\n",
       "       [ 0.616491  ],\n",
       "       [ 4.71355797],\n",
       "       [ 1.87585502],\n",
       "       [ 3.04051795],\n",
       "       [ 1.18772995],\n",
       "       [ 3.86084618],\n",
       "       [ 3.22962226],\n",
       "       [ 4.22605035],\n",
       "       [ 5.34925953],\n",
       "       [ 1.02357954],\n",
       "       [ 2.57027435],\n",
       "       [ 5.47809385],\n",
       "       [ 5.56107439],\n",
       "       [ 5.58317615],\n",
       "       [ 6.32545552],\n",
       "       [ 5.62896853],\n",
       "       [ 0.97520288],\n",
       "       [ 4.42983996],\n",
       "       [ 4.2120966 ],\n",
       "       [ 1.70576028],\n",
       "       [ 4.83469983],\n",
       "       [ 3.93255919],\n",
       "       [ 1.23857902],\n",
       "       [-0.18235334],\n",
       "       [-0.21563142],\n",
       "       [ 3.83878403],\n",
       "       [ 1.68196027],\n",
       "       [ 0.86613117],\n",
       "       [ 3.58118828],\n",
       "       [ 5.66312986],\n",
       "       [ 5.65360592],\n",
       "       [ 2.82111807],\n",
       "       [ 4.98380728],\n",
       "       [ 6.23816804],\n",
       "       [ 1.35527523],\n",
       "       [ 2.13492591],\n",
       "       [ 3.05986152],\n",
       "       [ 3.43873006],\n",
       "       [ 2.3748772 ],\n",
       "       [ 2.55837444],\n",
       "       [ 2.08881517],\n",
       "       [ 4.90835299],\n",
       "       [ 0.78681988],\n",
       "       [ 1.73981262],\n",
       "       [ 5.62134378],\n",
       "       [ 5.90001418],\n",
       "       [ 5.60601467],\n",
       "       [ 3.80104533],\n",
       "       [ 1.65363754]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data, axis = 1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.31845368,  5.03182099]),\n",
       " array([-0.16595746,  0.5652674 ]),\n",
       " array([ 1.02645431,  4.76042375]),\n",
       " array([ 5.23493625, -0.81138851]),\n",
       " array([ 4.65710743, -0.08532351]),\n",
       " array([ 0.43746553,  4.93778385]),\n",
       " array([-0.12756373,  5.14296293]),\n",
       " array([ 4.18200738,  0.24819247]),\n",
       " array([ 2.87600545,  0.31479159]),\n",
       " array([-0.69508006,  5.03848976]),\n",
       " array([ 6.01348014,  1.87722666]),\n",
       " array([ 2.9474123 ,  1.77314375]),\n",
       " array([ 1.75628753,  2.37551454]),\n",
       " array([ 5.03394554, -1.66740986]),\n",
       " array([ 2.12307182,  0.44351119]),\n",
       " array([ 0.36540757,  1.19513818]),\n",
       " array([ 1.70772369,  0.2659606 ]),\n",
       " array([ 4.90757786,  0.56716088]),\n",
       " array([ 0.60512066,  4.87555125]),\n",
       " array([ 2.58702609,  0.66766873]),\n",
       " array([ 0.19570654,  5.73836612]),\n",
       " array([ 3.97078181,  0.39328234]),\n",
       " array([ 0.529354  ,  1.53627772]),\n",
       " array([ 1.43201064,  0.67135402]),\n",
       " array([ 3.89988459,  0.92433204]),\n",
       " array([ 0.11205488,  6.4072012 ]),\n",
       " array([ 0.33474371,  1.60398487]),\n",
       " array([ 0.56231532,  5.01349864]),\n",
       " array([ 1.20085198,  0.1737734 ]),\n",
       " array([-0.77578232,  4.62650898]),\n",
       " array([ 3.02320794,  1.52205219]),\n",
       " array([ 1.33617673, -0.25843313]),\n",
       " array([ 0.30824932,  0.53710577]),\n",
       " array([ 1.50563766,  2.03762281]),\n",
       " array([ 1.42888785,  0.8098507 ]),\n",
       " array([ 5.52201954,  0.46015202]),\n",
       " array([ 0.60220586,  1.3164312 ]),\n",
       " array([ 0.02126064,  4.76228496]),\n",
       " array([ 5.32547107,  1.46856369]),\n",
       " array([-0.14300403, -0.57387067]),\n",
       " array([ 0.182161  ,  4.44577711]),\n",
       " array([ 2.34848606,  1.86460275]),\n",
       " array([ 0.96555295,  1.34056994]),\n",
       " array([ 1.35150829,  0.0758924 ]),\n",
       " array([ 0.28487706,  4.5665366 ]),\n",
       " array([ 0.4764496 ,  5.72581327]),\n",
       " array([-0.23052365, -1.0924812 ]),\n",
       " array([-0.85376105,  4.17389402]),\n",
       " array([ 0.08542074,  4.38781614]),\n",
       " array([ 0.21418408,  5.60131432]),\n",
       " array([-0.29932464,  4.62574683]),\n",
       " array([ 0.87644884, -0.25995784]),\n",
       " array([ 4.77358263, -0.06002466]),\n",
       " array([ 0.60031947,  1.27553555]),\n",
       " array([ 1.43768795,  1.60283   ]),\n",
       " array([ 0.06897793,  1.11875201]),\n",
       " array([-0.25767001,  4.11851619]),\n",
       " array([ 1.79020865,  1.43941361]),\n",
       " array([-0.34493741,  4.57098776]),\n",
       " array([ 4.71632515,  0.63293438]),\n",
       " array([ 0.69927439,  0.32430515]),\n",
       " array([ 2.07323075,  0.4970436 ]),\n",
       " array([ 5.46625127,  0.01184258]),\n",
       " array([ 2.23408932,  3.32698507]),\n",
       " array([ 0.01458455,  5.5685916 ]),\n",
       " array([ 1.49605116,  4.82940436]),\n",
       " array([ 5.75963176, -0.13066323]),\n",
       " array([ 0.67624054,  0.29896233]),\n",
       " array([ 4.76328545, -0.33344549]),\n",
       " array([ 3.13705596,  1.07504064]),\n",
       " array([ 1.32487484,  0.38088545]),\n",
       " array([-0.20028537,  5.0349852 ]),\n",
       " array([-0.79147695,  4.72403614]),\n",
       " array([ 0.56661856,  0.67196046]),\n",
       " array([-0.38462294,  0.2022696 ]),\n",
       " array([-1.21852027,  1.00288885]),\n",
       " array([-0.1914201 ,  4.03020414]),\n",
       " array([ 1.14110488,  0.54085539]),\n",
       " array([ 1.10702058, -0.24088941]),\n",
       " array([ 1.9186801 ,  1.66250817]),\n",
       " array([-0.18786611,  5.85099597]),\n",
       " array([ 4.29931854,  1.35428737]),\n",
       " array([ 1.32290993,  1.49820814]),\n",
       " array([-0.8336478 ,  5.81745508]),\n",
       " array([ 3.69473972,  2.54342832]),\n",
       " array([ 1.19321846,  0.16205677]),\n",
       " array([ 1.15456349,  0.98036242]),\n",
       " array([ 1.55133977,  1.50852175]),\n",
       " array([-0.47669162,  3.91542167]),\n",
       " array([ 1.3446835,  1.0301937]),\n",
       " array([ 1.61737918,  0.94099526]),\n",
       " array([ 1.26772312,  0.82109205]),\n",
       " array([ 0.04638356,  4.86196943]),\n",
       " array([ 0.44809768,  0.3387222 ]),\n",
       " array([ 0.67876556,  1.06104705]),\n",
       " array([ 5.63522868, -0.0138849 ]),\n",
       " array([ 0.52699679,  5.37301739]),\n",
       " array([ 4.80426637,  0.8017483 ]),\n",
       " array([ 1.8067412 ,  1.99430414]),\n",
       " array([ 1.04481862,  0.60881891])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.19570654,  5.73836612]),\n",
       " array([ 6.01348014,  1.87722666]),\n",
       " array([ 0.52699679,  5.37301739])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_means = [data[x] for x in chosen]\n",
    "initial_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = loglikelihood(data, initial_weights, initial_means, initial_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31845368,  5.03182099])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b2b1ae83c086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Run EM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_covs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-3b0b3a293a09>\u001b[0m in \u001b[0;36mEM\u001b[1;34m(data, init_means, init_covariances, init_weights, maxiter, thresh)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mweighted_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_sum\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "# Initialization of parameters\n",
    "chosen = np.random.choice(len(data), 3, replace=False)\n",
    "initial_means = [data[x] for x in chosen]\n",
    "initial_covs = [np.cov(data, rowvar=0)] * 3\n",
    "initial_weights = [1/3.] * 3\n",
    "\n",
    "# Run EM \n",
    "results = EM(data, initial_means, initial_covs, initial_weights)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dato-env]",
   "language": "python",
   "name": "Python [dato-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
